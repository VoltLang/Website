---
title: Documentation
layout: page
---
<div class="section" id="an-overview-of-the-compilation-process">
<h1>An Overview of the Compilation Process</h1>
<p>The Volt compiler turns text files into object files, and can turn those object files into shared objects and executables. The latter is mostly handled by the linker (<tt class="docutils literal">gcc</tt>, by default, but this can be changed by using the <tt class="docutils literal"><span class="pre">--linker</span></tt> flag). With that in mind, this document will be a bird's eye view of the former process; turning a source file into an object.</p>
<div class="section" id="driver">
<h2>Driver</h2>
<p>The driver looks at the command line and figures out what to do. It sets flags in a Settings object, and gets a list of files that it wants to compile. It then creates a VoltController object, passes it this information and tells it to compile.</p>
<p>The first important thing the controller does, is create a Parser object and tell it to parse the files.</p>
</div>
</div>
<div class="section" id="parser">
<h1>Parser</h1>
<p>The parser works on a list of objects called Tokens. This is easier to work with and reason about than working with the characters directly. So to that end, the lexer is called to turn the source into a list of tokens.</p>
<div class="section" id="lexer">
<h2>Lexer</h2>
<p>The lexing process is all-in-all fairly simple. A Source object is first created, and given the raw data from the source file. This object handles decoding characters, script lines, BOMs -- all that fun stuff. The lexer functions just read the next character, and generate a Token -- if they see a '1' they generate a number token, 'a' an identifier token, and so on.</p>
<p>This is all for the most part free standing functions, and should be easy enough to read and follow along. Now that we've got our tokens, the parser proper can begin. The parser turns the tokens into an Intermediate Representation Tree, the IR for short.</p>
</div>
<div class="section" id="ir">
<h2>IR</h2>
<p>The IR is an abstract representation of the source file. That is to say, where the tokens are a concrete representation -- the tokens match up to the characters in the source file, for the most part -- the IR is abstract; it encodes abstract concept. For example, &quot;int a;&quot; might be a list of tokens &lt;int&gt; &lt;identifier:a&gt; &lt;semicolon&gt;, but the IR would be closer to Variable(Type(Int), &quot;a&quot;).</p>
<p>The parser is a recursive descent parser, and is handwritten. That is, it starts at <tt class="docutils literal">parseModule</tt>, the top-most IR node, and works its way down and gives you back an ir.Module with all your functions and variables and whatever attached to it.</p>
<p>All members of the IR tree are based on an ir.Node. Each node has a nodeType; an enum that tells you what member it is. A Location, that gives you the source filename, line number, and column number of where in the source file that IR node corresponds to. It also has an optional documentation comment attached in the docComment member, but that's not important right now.</p>
</div>
<div class="section" id="parsing">
<h2>Parsing</h2>
<p>Once you've got that in mind, the parser is pretty simple. It looks at the next token, determines what needs to be parsed, then generates the IR node needed, while consuming tokens, until it finds an error or runs out of source code.</p>
</div>
</div>
<div class="section" id="semantic">
<h1>Semantic</h1>
<p>So now we have one or more ir.Modules from the parser corresponding to the source files we were given. The backend works on these modules too, but they're not ready for that yet. The backend only works on a subset of the IR tree (see the IRVerifier for details), so the semantic phase massages the IR into an appropriate shape.</p>
<p>Essentially, the semantic phase makes the IR a lot more verbose. <tt class="docutils literal">auto i = 3;`</tt> will become <tt class="docutils literal">int i; i = 3;</tt>. Your fancy <tt class="docutils literal">foreach</tt> statements will be lowered into simple <tt class="docutils literal">for</tt> statements. The backend only knows how to generate top level functions, so methods and inline functions need to be hoisted to top level functions, with their context becoming structs.</p>
<p>Also, in theory, the IR should be verified sound by the time the semantic phase is done with it. No errors (in the user's code) should be detected in the backend. For example, the backend shouldn't need to check that <tt class="docutils literal">cast(int) var;</tt> is safe or sound -- it will assume it is.</p>
<p>So as you can imagine, all of the above is a fair amount of work, and doing it in one giant nest of functions is out of the question. All the transformations are broken into passes. A <tt class="docutils literal">Pass</tt> is a simple interface. It has a method <tt class="docutils literal">transform</tt> that takes a module, and a method <tt class="docutils literal">close</tt> that takes no arguments, for cleaning up.</p>
<div class="section" id="visitor">
<h2>Visitor</h2>
<p>It's probably obvious, but these passes are going to spend a lot of time traversing the IR tree looking at things. The visitor code implements a visitor pattern for visiting the Volt IR, so the passes can inherit from the Visitor interface (or usually, the NullVisitor object -- an implementation of Visitor that does nothing for each node), and then call accept on themselves to traverse the tree.</p>
</div>
<div class="section" id="passes">
<h2>Passes</h2>
<p>The passes work like a pipeline. They're run one after the other, on the same module, and each subsequent pass works on the result of the prior. So every pass after the conditional removal pass can assume they'll not see a static if or version block. Speaking of which, let's briefly go over the passes. Some are more significant than others.</p>
</div>
<div class="section" id="conditionalremoval">
<h2>ConditionalRemoval</h2>
<p>This pass evaluates version blocks, debug blocks, static ifs and the like, and removes blocks of code that need to be removed. Most of the code in this pass is concerned with the pruning of the tree, and making sure it still looks sane afterwards.</p>
</div>
<div class="section" id="scopereplacer">
<h2>ScopeReplacer</h2>
<p>Takes the scope (exit/success/failure) blocks from functions, turns them into inline function, and adds a reference to the new function to a list on the parent Function object.</p>
</div>
<div class="section" id="attribremoval">
<h2>AttribRemoval</h2>
<p>Attributes are those flags that work on top level blocks, that you can place colons after. <tt class="docutils literal">public</tt>, <tt class="docutils literal">private</tt>, <tt class="docutils literal">extern</tt>, etc. This pass works out what nodes which attributes apply to, and turns them into appropriate fields -- Functions will have their access and linkage fields set, and so on.</p>
</div>
</div>
